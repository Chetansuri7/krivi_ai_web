
---- app/components/chat/ModelSelector.tsx ----
// app/components/chat/ModelSelector.tsx
import { ChevronDownIcon, FileDownIcon } from 'lucide-react';
import type { AIModelConfig } from '~/lib/ai-models'; // Adjust path as needed

interface ModelSelectorProps {
  models: AIModelConfig[];
  selectedModel: AIModelConfig;
  onModelChange: (model: AIModelConfig) => void;
  disabled?: boolean;
  className?: string; // Allow passing custom classes
}

export function ModelSelector({
  models,
  selectedModel,
  onModelChange,
  disabled,
  className,
}: ModelSelectorProps) {
  const handleChange = (event: React.ChangeEvent<HTMLSelectElement>) => {
    const selected = models.find(
      (m) =>
        m.model === event.target.value &&
        m.provider ===
          event.target.options[event.target.selectedIndex].dataset.provider
    );
    if (selected) {
      onModelChange(selected);
    }
  };

  return (
    <div className={`inline-block relative ${className || ''}`}>
      <select
        value={selectedModel.model} // Ensure value matches one of the option values
        onChange={handleChange}
        disabled={disabled}
        className="appearance-none text-xs font-medium bg-background hover:bg-muted border border-input rounded-md px-2.5 py-1.5 pr-7 focus:ring-1 focus:ring-primary focus:outline-none focus:border-primary disabled:opacity-70 disabled:cursor-not-allowed"
      >
        {models.map((model) => (
          <option
            key={`${model.provider}-${model.model}`}
            value={model.model}
            data-provider={model.provider}
          >
            {model.displayName}
          </option>
        ))}
      </select>
      <div className="pointer-events-none absolute inset-y-0 right-0 flex items-center px-1.5 text-muted-foreground">
        <ChevronDownIcon className="h-4 w-4" /> {/* Changed icon and slightly increased size */}
      </div>
    </div>
  );
}
---- app/components/chat/ChatInputBar.tsx ----
// app/components/chat/ChatInputBar.tsx
import React, { useRef, useEffect, useState } from 'react';
import { ArrowUp, Paperclip, Settings2, Brain } from 'lucide-react'; // Added Brain
import type { AIModelConfig } from '~/lib/ai-models';
import { ModelSelector } from './ModelSelector'; // Import ModelSelector
import { Switch } from '~/components/ui/switch';
import { Label } from '~/components/ui/label';

const isProbablyMobile = () => typeof window !== 'undefined' && window.innerWidth < 768;

interface ChatInputBarProps {
  input: string;
  onInputChange: (event: React.ChangeEvent<HTMLTextAreaElement>) => void;
  onSubmit: (options: { thinkingEnabled?: boolean }) => void; // Modified onSubmit
  isLoading: boolean;
  availableModels: AIModelConfig[];
  selectedModel: AIModelConfig;
  onModelChange: (model: AIModelConfig) => void;
}

const MIN_TEXTAREA_HEIGHT_REM = 1.625;
const TEXTAREA_PADDING_Y_PX = 20; 
const MAX_TEXTAREA_HEIGHT_PX = 144; 

export function ChatInputBar({
  input,
  onInputChange,
  onSubmit,
  isLoading,
  availableModels,
  selectedModel,
  onModelChange,
}: ChatInputBarProps) {
  const textareaRef = useRef<HTMLTextAreaElement>(null);
  const [thinkingEnabled, setThinkingEnabled] = useState(false);

  useEffect(() => {
    // Reset thinking toggle if model changes and doesn't support it
    if (!selectedModel?.uiOptions?.thinkingToggleSettings) {
      setThinkingEnabled(false);
    }
  }, [selectedModel]);

  useEffect(() => {
    const textarea = textareaRef.current;
    if (textarea) {
      textarea.style.height = 'auto'; 
      const scrollHeight = textarea.scrollHeight;
      const newHeight = Math.min(scrollHeight, MAX_TEXTAREA_HEIGHT_PX);
      textarea.style.height = `${newHeight}px`;
    }
  }, [input]);

  const handleTextareaKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    const mobile = isProbablyMobile();
    if (e.key === 'Enter' && (e.shiftKey || e.ctrlKey)) return; 
    if (mobile && e.key === 'Enter') return; 
    if (e.key === 'Enter' && !mobile) {
      e.preventDefault();
      if (!isLoading && (input || '').trim()) {
        const form = e.currentTarget.form;
        if (form) form.requestSubmit();
      }
    }
  };

  const isSendDisabled = isLoading || !(input || '').trim();

  return (
    <div className="w-full flex-shrink-0">
      <form
        onSubmit={(e) => {
          e.preventDefault();
          if (!isLoading && (input || '').trim()) {
            onSubmit({ thinkingEnabled: selectedModel?.uiOptions?.thinkingToggleSettings ? thinkingEnabled : undefined });
          }
        }}
        className="relative mx-auto flex w-full flex-col rounded-xl bg-card p-2.5 shadow-xl ring-1 ring-border sm:p-3"
      >
        <textarea
          ref={textareaRef}
          value={input || ''}
          onChange={onInputChange}
          onKeyDown={handleTextareaKeyDown}
          placeholder={selectedModel ? `Ask ${selectedModel.displayName}...` : 'Select a model...'}
          rows={1}
          className="w-full resize-none overflow-y-auto rounded-lg border-none bg-transparent px-3 py-2.5 text-base text-foreground outline-none placeholder:text-muted-foreground focus:ring-0"
          style={{
            minHeight: `calc(${MIN_TEXTAREA_HEIGHT_REM}rem + ${TEXTAREA_PADDING_Y_PX}px)`,
            maxHeight: `${MAX_TEXTAREA_HEIGHT_PX}px`,
          }}
          disabled={isLoading}
          aria-label="Chat message input"
        />
        <div className="mt-2 flex items-center justify-between">
          <div className="flex items-center gap-1.5">
            <ModelSelector
              models={availableModels}
              selectedModel={selectedModel}
              onModelChange={onModelChange}
              disabled={isLoading || !availableModels || availableModels.length === 0}
            />
            {selectedModel?.uiOptions?.thinkingToggleSettings && (
              <div className="flex items-center space-x-2 ml-2">
                <Switch
                  id="thinking-toggle"
                  checked={thinkingEnabled}
                  onCheckedChange={setThinkingEnabled}
                  disabled={isLoading}
                />
                <Label htmlFor="thinking-toggle" className="flex items-center text-sm text-primary cursor-pointer select-none">
                  <Brain className="w-4 h-4 mr-1" />
                  AI Thinking
                </Label>
              </div>
            )}
          </div>
          <div className="flex items-center gap-1 sm:gap-1.5">
            <button type="button" className="p-1.5 text-muted-foreground hover:text-foreground hover:bg-muted sm:p-2 rounded-md disabled:opacity-50" disabled={true} title="Attach file (soon)">
              <Paperclip size={18} strokeWidth={2} />
            </button>
            <button type="button" className="p-1.5 text-muted-foreground hover:text-foreground hover:bg-muted sm:p-2 rounded-md disabled:opacity-50" disabled={true} title="Model options (soon)">
              <Settings2 size={18} strokeWidth={2} />
            </button>
            <button type="submit" className="flex items-center justify-center rounded-lg bg-primary px-3 py-2 text-primary-foreground hover:bg-primary/90 disabled:opacity-50" disabled={isSendDisabled} title="Send message">
              <ArrowUp size={20} strokeWidth={2.25} />
            </button>
          </div>
        </div>
      </form>
    </div>
  );
}
---- app/components/chat/MessageList.tsx ----
// app/components/MessageList.tsx
import type { RefObject } from 'react';
import type { Message } from './MessageItem'; // Assuming MessageItem exports Message type
import { MessageItem } from './MessageItem';

interface MessageListProps {
  messages: Message[];
  isLoading: boolean; // This prop is now only for isInitialHistoryLoading visual cues if any, or can be removed if not used elsewhere
  isInitialHistoryLoading?: boolean;
  scrollEndRef: RefObject<HTMLDivElement>;
}

export function MessageList({
  messages,
  // isLoading, // This prop is no longer used for the assistant typing indicator here
  isInitialHistoryLoading = false, // Keep if used for other purposes
  scrollEndRef,
}: MessageListProps) {
  return (
    <div className="p-4 space-y-4"> {/* Ensure this padding is desired, or remove if MessageItem handles it */}
      {messages.map((msg) => (
        <MessageItem key={msg.id} message={msg} />
      ))}
      
      <div ref={scrollEndRef} style={{ height: '1px' }} />
    </div>
  );
}
---- app/components/chat/InitialGreeting.tsx ----
// app/components/chat/InitialGreeting.tsx  
import React from "react";  
  
export function InitialGreeting() {  
  return (  
<div className="flex flex-1 flex-col justify-center items-center min-h-0">  
      <h1 className="text-3xl md:text-4xl font-semibold mb-2 text-neutral-900 dark:text-neutral-100 text-center">  
        How can I help you today?  
      </h1>  
      <div className="h-1 w-24 bg-primary/40 rounded-full my-4" />  
      <p className="text-neutral-500 dark:text-neutral-400 text-center">  
        Start typing below or ask anything.  
      </p>  
    </div>  
  );  
}  
---- app/components/chat/MessageItem.tsx ----
// app/components/MessageItem.tsx
import React, { useState, useRef, Fragment } from "react";
import { Markdown } from "../Markdown";
import { Check, Copy, Loader, MessageCircle, Sparkles, ChevronDown, ChevronUp } from "lucide-react";
import {
  Collapsible,
  CollapsibleContent,
  CollapsibleTrigger,
} from "~/components/ui/collapsible";

export interface Message {
  id: string;
  role: "user" | "assistant" | "system"; // Added "system"
  content: string;
  isLoading?: boolean;
}

interface MessageItemProps {
  message: Message;
}

export function MessageItem({ message }: MessageItemProps) {
  const isUser = message.role === "user";
  const isAssistant = message.role === "assistant";
  const contentBubbleRef = useRef<HTMLDivElement>(null);

  const [copied, setCopied] = useState(false);

  const handleCopy = (textToCopy: string) => {
    navigator.clipboard.writeText(textToCopy).then(() => {
      setCopied(true);
      setTimeout(() => setCopied(false), 1500);
    });
  };

  const parseMessageContent = (content: string) => {
    const parts = [];
    let lastIndex = 0;
    const regex = /<think>([\s\S]*?)<\/think>|<think>([\s\S]*?)<\/think>/gs;
    let match;

    while ((match = regex.exec(content)) !== null) {
      if (match.index > lastIndex) {
        parts.push({ type: "text", content: content.substring(lastIndex, match.index) });
      }
      // Group 1 is for <think>, Group 2 is for <think>
      const thinkContent = match[1] || match[2];
      parts.push({ type: "think", content: thinkContent.trim() });
      lastIndex = regex.lastIndex;
    }

    if (lastIndex < content.length) {
      parts.push({ type: "text", content: content.substring(lastIndex) });
    }
    return parts;
  };


  function AssistantIconRow() {
    return (
      <div className="flex items-center gap-3 mb-2 select-none">
        <div className="w-9 h-9 flex items-center justify-center rounded-full bg-gray-100 shadow text-indigo-700">
          <MessageCircle className="w-6 h-6" />
        </div>
        <span className="italic text-base mr-2">Krivi AI</span>
        {message.isLoading ? (
          <div className="flex items-center gap-2 text-muted-foreground text-sm">
            <Loader className="w-5 h-5 animate-spin" />
            <span>Assistant is typing...</span>
          </div>
        ) : null}
      </div>
    );
  }

  if (isAssistant && message.isLoading && !message.content) {
    return (
      <div
        id={`message-${message.id}`}
        className="flex justify-start mb-4"
        data-role={message.role}
      >
        <div className="flex flex-col items-start max-w-[100%]">
          <AssistantIconRow />
        </div>
      </div>
    );
  }

  return (
    <div
      id={`message-${message.id}`}
      className={`flex ${isUser ? "justify-end" : "justify-start"} mb-4`}
      data-role={message.role}
    >
      <div
        className={`max-w-[100%] flex flex-col ${isUser ? "items-end" : "items-start"}`}
      >
        {isAssistant && <AssistantIconRow />}
        <div
          ref={contentBubbleRef}
          className={
            isUser
              ? "shadow rounded-lg px-3 py-2 bg-primary text-primary-foreground"
              : "prose prose-sm text-foreground p-3"
          }
          style={{
            maxWidth: "100%",
            overflowWrap: "break-word",
            overflowX: "auto",
          }}
        >
          {message.content ? (
            parseMessageContent(message.content).map((part, index) => {
              if (part.type === "think") {
                return (
                  <ThinkBlock key={index} content={part.content} />
                );
              }
              return (
                <Markdown key={index}>{part.content}</Markdown>
              );
            })
          ) : (isUser ? <span> </span> : null)}
        </div>
        {message.content && !message.isLoading && (
          <div className={`flex mt-1 ${isUser ? "justify-end" : "justify-start"}`}>
            <button
              onClick={() => handleCopy(message.content)}
              className="text-muted-foreground hover:text-foreground transition-colors p-1 rounded hover:bg-muted flex items-center gap-1 text-xs"
              aria-label={copied ? "Copied!" : "Copy message"}
            >
              {copied ? (
                <>
                  <Check className="w-3 h-3" />
                  <span>Copied!</span>
                </>
              ) : (
                <>
                  <Copy className="w-3 h-3" />
                  <span>Copy</span>
                </>
              )}
            </button>
          </div>
        )}
      </div>
    </div>
  );
}

interface ThinkBlockProps {
  content: string;
}

function ThinkBlock({ content }: ThinkBlockProps) {
  const [isOpen, setIsOpen] = useState(true); // Default to expanded

  return (
    <Collapsible open={isOpen} onOpenChange={setIsOpen} className="my-2">
      {/* Trigger button with its own background (white/dark gray) and shadow, always rounded */}
      <CollapsibleTrigger
        className={`flex items-center gap-2 p-2 bg-white dark:bg-gray-800 hover:bg-gray-50 dark:hover:bg-gray-700 text-sm font-medium focus-visible:ring-1 focus-visible:ring-ring focus-visible:outline-none w-fit shadow rounded-md`}
      >
        <div className="flex items-center gap-2 text-slate-700 dark:text-slate-200">
          <Sparkles className="w-4 h-4 text-purple-500" />
          <span>Thinking...</span>
        </div>
        {isOpen ? <ChevronUp className="w-4 h-4 text-slate-500 dark:text-slate-400" /> : <ChevronDown className="w-4 h-4 text-slate-500 dark:text-slate-400" />}
      </CollapsibleTrigger>
      
      {/* Content area with its own background (white/dark gray), border, and shadow, appearing below the trigger */}
      <CollapsibleContent className="mt-1 pt-2 pb-3 px-3 bg-white dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-md shadow-sm">
        <div className="pl-3 border-l-2 border-purple-400 dark:border-purple-600 max-h-[300px] overflow-y-auto">
          <div className="prose prose-sm max-w-full text-slate-600 dark:text-slate-400 [&_p]:text-sm">
            <Markdown>{content}</Markdown>
          </div>
        </div>
      </CollapsibleContent>
    </Collapsible>
  );
}
---- app/components/chat/streaming-chat-context.tsx ----
// app/components/chat/streaming-chat-context.tsx
import React, { createContext, useContext, useState, useRef, useCallback, useEffect } from 'react';
import type { Message } from '~/components/chat/MessageItem';
import type { AIModelConfig } from '~/lib/ai-models';
import { API_STREAM_URL, defaultSystemPrompt } from '~/lib/ai-models';
import { fetchWithHeaders } from '~/lib/api.config';

interface StreamData {
  chatId?: string; // Backend might still send this, but we won't use it for session ID determination
  content?: string;
  type?: 'metadata' | 'content_start' | 'stream_end' | 'error' | 'usage_summary' | 'chat_id_update';
  error?: { message: string };
}

export interface StreamingChatContextType {
  messages: Message[];
  isStreaming: boolean;
  streamError: string | null;
  activeStreamChatId: string | null; // ChatId of the stream being processed
  currentUIFocusChatId: string | null; // ChatId the UI is currently focused on
  startStream: (
    prompt: string,
    modelConfig: AIModelConfig,
    chatIdToStream: string, // Authoritative Chat ID for this stream
    thinkingEnabled?: boolean, // Added thinkingEnabled
  ) => Promise<void>; // No longer returns a chatId, as frontend dictates it
  abortStream: (reason?: string) => void;
  setMessagesForContext: (messages: Message[], uiFocusedChatId: string | null) => void;
  clearStreamState: () => void;
}

const StreamingChatContext = createContext<StreamingChatContextType | undefined>(undefined);

export const StreamingChatProvider = ({ children }: { children: React.ReactNode }) => {
  const [messages, setMessages] = useState<Message[]>([]);
  const [isStreaming, setIsStreaming] = useState(false);
  const [streamError, setStreamError] = useState<string | null>(null);
  const [activeStreamChatId, setActiveStreamChatId] = useState<string | null>(null);
  const [currentUIFocusChatId, setCurrentUIFocusChatId] = useState<string | null>(null);

  const abortControllerRef = useRef<AbortController | null>(null);
  const currentAssistantMessageIdRef = useRef<string | null>(null);

  /**
   * Exported so that history loaders can reuse the same normalization logic.
   */
  /**
   * Exported so that history loaders can reuse the same normalization logic.
   */
  
function normalizeMessagesForUI(messages: any[]): Message[] {
  return messages.map((msg) => {
    let mainContent: string = typeof msg.content === "string" ? msg.content : "";
    if (typeof msg.thought === "string" && msg.thought.trim()) {
      mainContent = mainContent + `<think>${msg.thought.trim()}</think>`;
    }
    if (typeof msg.query === "string" && msg.query.trim()) {
      mainContent = mainContent + `<think>Query: ${msg.query.trim()}</think>`;
    }
    const { thought, query, ...rest } = msg;
    return { ...rest, content: mainContent };
  });
}

export { normalizeMessagesForUI };

  const setMessagesForContext = useCallback((newMessages: Message[], uiFocusedChatId: string | null) => {
    console.log(`Context: setMessagesForContext called. New messages count: ${newMessages.length}, UI Focus: ${uiFocusedChatId}, Current Active Stream: ${activeStreamChatId}`);
    setMessages(normalizeMessagesForUI(newMessages));
    setCurrentUIFocusChatId(uiFocusedChatId);

    if (activeStreamChatId && uiFocusedChatId !== activeStreamChatId && isStreaming) {
      console.log(`Context: UI focus changed to ${uiFocusedChatId} from active stream ${activeStreamChatId}. Aborting stream.`);
      abortControllerRef.current?.abort("UI context changed away from active stream");
      // Reset streaming states, message updates handled by abortStream/finally in startStream
      setIsStreaming(false);
      // setActiveStreamChatId(null); // Keep activeStreamChatId until a new stream starts or state is cleared
      if (currentAssistantMessageIdRef.current) {
        setMessages(prev => prev.map(msg => msg.id === currentAssistantMessageIdRef.current && msg.isLoading ? { ...msg, isLoading: false, content: msg.content || "[Stream context changed]" } : msg));
        currentAssistantMessageIdRef.current = null;
      }
    }
  }, [activeStreamChatId, isStreaming]);

  const clearStreamState = useCallback(() => {
    console.log("Context: clearStreamState called.");
    if (isStreaming && abortControllerRef.current) {
      abortControllerRef.current.abort("Clearing stream state");
    }
    setMessages([]);
    setIsStreaming(false);
    setStreamError(null);
    setActiveStreamChatId(null);
    setCurrentUIFocusChatId(null);
    currentAssistantMessageIdRef.current = null;
    if (abortControllerRef.current) {
      abortControllerRef.current = null;
    }
  }, [isStreaming]);

  const abortStream = useCallback((reason: string = "User requested abort") => {
    if (abortControllerRef.current && !abortControllerRef.current.signal.aborted) {
      console.log(`Context: Aborting stream. Reason: ${reason}`);
      abortControllerRef.current.abort(reason);
    }
    // Ensure state is updated even if abort is called externally / multiple times
    if (isStreaming) {
      setIsStreaming(false);
      if (currentAssistantMessageIdRef.current) {
        setMessages(prev =>
          prev.map(msg =>
            msg.id === currentAssistantMessageIdRef.current && msg.isLoading
              ? { ...msg, isLoading: false, content: msg.content || `[Stream aborted: ${reason}]` }
              : msg
          )
        );
        currentAssistantMessageIdRef.current = null;
      }
    }
    // abortControllerRef.current = null; // Will be reset on next startStream
  }, [isStreaming]);

  const startStream = useCallback(
    async (
      prompt: string,
      modelConfig: AIModelConfig,
      chatIdToStream: string, // Authoritative Chat ID (frontend-generated for new)
      thinkingEnabled?: boolean, // Added thinkingEnabled
    ): Promise<void> => {
      if (isStreaming && abortControllerRef.current && !abortControllerRef.current.signal.aborted) {
        console.warn("Context: Stream already in progress. Aborting previous to start new one.");
        abortControllerRef.current.abort("New stream started, superceded by new request.");
      }

      console.log(`Context: startStream called for chatId: ${chatIdToStream}`);
      setIsStreaming(true);
      setStreamError(null);
      setActiveStreamChatId(chatIdToStream); // This stream is for this ID

      // The user message should already be in `messages` via `setMessagesForContext`
      // We only add the assistant placeholder here.
      const assistantMsgId = crypto.randomUUID();
      currentAssistantMessageIdRef.current = assistantMsgId;
      const assistantPlaceholder: Message = { id: assistantMsgId, role: 'assistant', content: '', isLoading: true };

      setMessages(prevMessages => [...prevMessages, assistantPlaceholder]);

      abortControllerRef.current = new AbortController();

      try {
        const response = await fetchWithHeaders(API_STREAM_URL, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json', 'Accept': 'text/event-stream' },
          body: JSON.stringify((() => {
            const modelId = modelConfig.model; // Use modelId as key, value from modelConfig.model
            const provider = modelConfig.provider;

            // Initialize messages array for the payload
            let messagesForPayload: Array<{role: string, content: string}> = [];

            // Start with messages from modelConfig.requestPayload if they exist, mapping to {role, content}
            // This ensures any pre-defined messages (like a specific system prompt from model config) are included.
            if (modelConfig.requestPayload && Array.isArray(modelConfig.requestPayload.messages)) {
                messagesForPayload = modelConfig.requestPayload.messages.map((m: any) => ({
                    role: m.role,
                    content: m.content
                })).filter((m: any) => typeof m.role === 'string' && typeof m.content === 'string'); // Ensure valid messages
            }

            // Add or Update user message (current input 'prompt')
            // If a 'user' message already exists (e.g. from modelConfig.requestPayload.messages), update its content.
            // Otherwise, add the new user message.
            let userMessageFound = false;
            messagesForPayload = messagesForPayload.map(m => {
                if (m.role === 'user') {
                    userMessageFound = true;
                    return { ...m, content: prompt };
                }
                return m;
            });
            if (!userMessageFound) {
                messagesForPayload.push({ role: 'user', content: prompt });
            }

            // Add or Update system message (using defaultSystemPrompt)
            // If a 'system' message exists (e.g. from modelConfig.requestPayload.messages) and its content is empty,
            // and defaultSystemPrompt is defined, fill the content.
            // If no 'system' message exists and defaultSystemPrompt is defined, add it (typically at the beginning).
            let systemMessageFound = false;
            messagesForPayload = messagesForPayload.map(m => {
                if (m.role === 'system') {
                    systemMessageFound = true;
                    if (!m.content && defaultSystemPrompt) {
                        return { ...m, content: defaultSystemPrompt };
                    }
                }
                return m;
            });
            if (!systemMessageFound && defaultSystemPrompt) {
                messagesForPayload.unshift({ role: 'system', content: defaultSystemPrompt });
            }
            
            // Final filter to ensure all messages in the payload have a role and string content.
            messagesForPayload = messagesForPayload.filter(m => m.role && typeof m.content === 'string');

            return {
              chatId: chatIdToStream,
              provider: provider,
              modelId: modelId, // Key is now modelId
              messages: messagesForPayload, // Messages array is top-level
            };
          })()),
          signal: abortControllerRef.current.signal,
          credentials: 'include',
        });

        if (abortControllerRef.current.signal.aborted) {
          console.log("Context: Stream fetch aborted before response fully processed.");
          // Message update is handled in finally or if abortStream was called directly
          return;
        }

        if (!response.ok || !response.body) {
          const errorBody = await response.text().catch(() => "Failed to read error body");
          setStreamError(`API Error ${response.status}: ${errorBody}`);
          setMessages(prev => prev.map(m => m.id === assistantMsgId ? { ...m, isLoading: false, content: `API Error: ${response.status}` } : m));
          setIsStreaming(false);
          currentAssistantMessageIdRef.current = null;
          return;
        }

        const reader = response.body.getReader();
        const decoder = new TextDecoder();
        let buffer = "";

        // Local scope thought buffer/state, safe for current request chunk loop
        let thoughtBuffer = "";
        let thoughtState: string | null = null;

        while (true) {
          const { done, value } = await reader.read();
          if (abortControllerRef.current?.signal.aborted) {
            console.log("Context: Stream processing loop aborted by signal.");
            break;
          }
          if (done) {
            console.log("Context: Stream finished naturally.");
            break;
          }

          buffer += decoder.decode(value, { stream: true });
          let newlineIndex;
          while ((newlineIndex = buffer.indexOf('\n')) >= 0) {
            const line = buffer.slice(0, newlineIndex).trim();
            buffer = buffer.slice(newlineIndex + 1);

            if (line.startsWith("data: ")) {
              const jsonDataString = line.substring(5);
              if (jsonDataString && !abortControllerRef.current?.signal.aborted) {
                try {
                  const chunk: any = JSON.parse(jsonDataString);

                  // --- THOUGHT-AWARE STREAM HANDLING ---
                  // Covers Google "thought": true with content next, OpenAI "thought": "string", "type": "think"
                  if (chunk.thought === true) {
                    // next chunk's .content is for thought only
                    thoughtState = "expecting-thought-content";
                  }
                  else if (
                    typeof chunk.thought === "string" &&
                    chunk.thought.trim().length > 0
                  ) {
                    thoughtBuffer += chunk.thought;
                  }
                  else if (
                    (chunk.type === "think" || chunk.type === "thought") &&
                    typeof chunk.content === "string"
                  ) {
                    thoughtBuffer += chunk.content;
                  }
                  // Now process regular content
                  if (
                    typeof chunk.content === "string" &&
                    chunk.content.length > 0
                  ) {
                    if (thoughtState === "expecting-thought-content") {
                      thoughtBuffer += chunk.content;
                      thoughtState = null;
                    } else if (thoughtBuffer) {
                      setMessages(prev =>
                        prev.map(msg =>
                          msg.id === assistantMsgId
                            ? {
                                ...msg,
                                content: msg.content + `<think>${thoughtBuffer}</think>` + chunk.content,
                                isLoading: true,
                              }
                            : msg
                        )
                      );
                      thoughtBuffer = "";
                    } else {
                      setMessages(prev =>
                        prev.map(msg =>
                          msg.id === assistantMsgId
                            ? { ...msg, content: msg.content + chunk.content, isLoading: true }
                            : msg
                        )
                      );
                    }
                  } else if (
                    thoughtBuffer && (
                      chunk.type === "stream_end" ||
                      chunk.type === "usage_summary"
                    )
                  ) {
                    setMessages(prev =>
                      prev.map(msg =>
                        msg.id === assistantMsgId
                          ? { ...msg, content: msg.content + `<think>${thoughtBuffer}</think>` }
                          : msg
                      )
                    );
                    thoughtBuffer = "";
                  }

                  if (chunk.type === 'chat_id_update' && chunk.chatId && chunk.chatId !== chatIdToStream) {
                    console.warn(`Context: Backend sent a chatId ${chunk.chatId} different from frontend's ${chatIdToStream}. Ignoring backend's for session ID.`);
                  }

                  if (chunk.type === 'stream_end' || chunk.type === 'usage_summary') {
                    if (!abortControllerRef.current?.signal.aborted) {
                      setMessages(prev => prev.map(msg => msg.id === assistantMsgId ? { ...msg, isLoading: false } : msg));
                      setIsStreaming(false);
                      currentAssistantMessageIdRef.current = null;
                      thoughtBuffer = "";
                      thoughtState = null;
                    }
                  } else if (chunk.error) {
                    if (!abortControllerRef.current?.signal.aborted) {
                      setStreamError(chunk.error?.message || "Stream error from backend");
                      setMessages(prev => prev.map(m =>
                        m.id === assistantMsgId
                          ? { ...m, isLoading: false, content: `${m.content || ""}\n[Error: ${chunk.error?.message ?? "Unknown error"}]` }
                          : m
                      ));
                      setIsStreaming(false);
                      currentAssistantMessageIdRef.current = null;
                      thoughtBuffer = "";
                      thoughtState = null;
                    }
                    break;
                  }

                  if (chunk.type === 'error' || chunk.error) break;

                } catch (e: any) {
                  if (!abortControllerRef.current?.signal.aborted) {
                    console.error("Context: Error parsing stream data JSON:", e, jsonDataString);
                    setStreamError(`Error parsing stream: ${e.message}`);
                    setMessages(prev => prev.map(m => m.id === assistantMsgId ? { ...m, isLoading: false, content: `${m.content || ""}\n[Error parsing stream data]` } : m));
                    setIsStreaming(false);
                    currentAssistantMessageIdRef.current = null;
                    thoughtBuffer = "";
                    thoughtState = null;
                  }
                  break;
                }
              }
            }
          }
        }
        // After finishing both loops (while(true) and while(line)),
        // mark as not loading if we exited without error/abort, just like original code.
        if (!abortControllerRef.current?.signal.aborted && isStreaming) { // Stream ended naturally by `done` or outer break
          setIsStreaming(false);
          setMessages(prev => prev.map(msg => msg.id === assistantMsgId && msg.isLoading ? { ...msg, isLoading: false } : msg));
          currentAssistantMessageIdRef.current = null;
        }
      } catch (error: any) {
        if (error.name === 'AbortError' || abortControllerRef.current?.signal.aborted) {
          console.log(`Context: Stream operation was aborted. Message: ${error.message}`);
          if (isStreaming) setIsStreaming(false);
          setMessages(prev => prev.map(msg => msg.id === assistantMsgId && msg.isLoading ? { ...msg, isLoading: false, content: msg.content || `[Stream aborted]` } : msg));
        } else {
          console.error("Context: Send/Stream error:", error);
          setStreamError(error.message || "An unknown error occurred.");
          setMessages(prev =>
            prev.map(msg =>
              msg.id === assistantMsgId
                ? { ...msg, content: (msg.content || "") + `\n[Error: ${error.message}]`, isLoading: false }
                : msg
            )
          );
          if (isStreaming) setIsStreaming(false);
        }
        if (currentAssistantMessageIdRef.current === assistantMsgId) {
          currentAssistantMessageIdRef.current = null;
        }
      } finally {
        // If stream ended, but not due to abort, and we are still marked as streaming (e.g. loop break), ensure cleanup.
        // This is a safeguard.
        if (isStreaming && (!abortControllerRef.current || !abortControllerRef.current.signal.aborted)) {
          setIsStreaming(false);
          if (currentAssistantMessageIdRef.current === assistantMsgId) {
            setMessages(prev => prev.map(msg => msg.id === assistantMsgId && msg.isLoading ? { ...msg, isLoading: false } : msg));
            currentAssistantMessageIdRef.current = null;
          }
        }
        // The AbortController instance is specific to this call of startStream.
        // It's fine if abortControllerRef.current is overwritten by a subsequent call.
      }
    },
    [isStreaming, abortStream] // Removed currentUIFocusChatId, as chatIdToStream is authoritative
  );

  useEffect(() => {
    return () => {
      if (abortControllerRef.current && !abortControllerRef.current.signal.aborted) {
        console.log("StreamingChatProvider unmounting, aborting any active non-aborted stream.");
        abortControllerRef.current.abort("Provider unmounted");
      }
      abortControllerRef.current = null;
    };
  }, []);

  const contextValue: StreamingChatContextType = {
    messages,
    isStreaming,
    streamError,
    activeStreamChatId,
    currentUIFocusChatId,
    startStream,
    abortStream,
    setMessagesForContext,
    clearStreamState,
  };

  return <StreamingChatContext.Provider value={contextValue}>{children}</StreamingChatContext.Provider>;
};

export const useStreamingChat = (): StreamingChatContextType => {
  const context = useContext(StreamingChatContext);
  if (!context) {
    throw new Error('useStreamingChat must be used within a StreamingChatProvider');
  }
  return context;
};
---- app/components/chat/ChatPageLayout.tsx ----
// app/components/chat/ChatPageLayout.tsx  
import React, { useState, useRef, useTransition as useReactTransitionHook, useEffect } from 'react';  
import { useNavigate, useLocation, useNavigation as useRemixNavigation, useParams } from '@remix-run/react';  
import { AImodels, defaultModelConfig } from '~/lib/ai-models';  
import { useScrollToBottom } from '~/hooks/useScrollToBottom';  
import { FiArrowDown } from 'react-icons/fi';  
import { useStreamingChat } from '~/components/chat/streaming-chat-context';  
import { InitialGreeting } from './InitialGreeting';  
import { useSidebarChatHistory } from '~/components/sidebar-chat-history-context';  
import { MessageList } from './MessageList';  
import { ChatInputBar } from './ChatInputBar';  
  
import { usePerChatModelSelection } from '~/hooks/usePerChatModelSelection';  
import { useChatSessionMessages } from '~/hooks/useChatSessionMessages';  
import { useSidebarHistoryRefreshOnChatChange } from '~/hooks/useSidebarHistoryRefreshOnChatChange';  
import { useChatSendMessage } from '~/hooks/useChatSendMessage';  
  
type ChatPageLayoutProps = {  
  initialChatIdFromLoader: string | null;  
  initialMessagesProp: any[];  
};  
  
export function ChatPageLayout({ initialChatIdFromLoader, initialMessagesProp }: ChatPageLayoutProps) {  
  const navigate = useNavigate();  
  const location = useLocation();  
  const params = useParams();  
  const urlChatId = params.chatId || null;  
  const remixNavigation = useRemixNavigation();  
  const [isReactTransitionPending, startReactTransition] = useReactTransitionHook();  
  const streamChat = useStreamingChat();  
  
  const [input, setInput] = useState('');  
  const [isNewChatTransitioning, setIsNewChatTransitioning] = useState(false);  
  
  const chatModelKey = urlChatId || 'new-chat';  
  
  // -- get scroll hook FIRST so scrollToBottom variable is ready before calling other hooks  
  const {  
    containerRef,  
    endRef,  
    showScrollDownButton,  
    scrollToBottom,  
    scrollToPartialView,  
    resetManualScrollFlag  
  } = useScrollToBottom(streamChat.messages);  
  
  const { selectedModel, handleModelChange } = usePerChatModelSelection(chatModelKey, defaultModelConfig);  
  
  const { chatPhase, setChatPhase } = useChatSessionMessages({  
    urlChatId,  
    initialMessagesProp,  
    streamChat,  
    location,  
    remixNavigation,  
    navigate,  
    startReactTransition,  
    isNewChatTransitioning,  
    setIsNewChatTransitioning,  
    scrollToBottom,  
  });  
  
  const lastSelectedModelMapRef = useRef<{ [key: string]: any }>({});  
  
  const handleSendMessage = useChatSendMessage({  
    streamChat,  
    urlChatId,  
    lastSelectedModelMapRef,  
    isReactTransitionPending,  
    chatPhase,  
    navigate,  
    startReactTransition,  
    setInput,  
    setIsNewChatTransitioning,  
    chatModelKey,  
  });  
  
  // For sidebar history  
  const { refreshChatHistory } = useSidebarChatHistory();  
  useSidebarHistoryRefreshOnChatChange(initialChatIdFromLoader, refreshChatHistory);  
  
  useEffect(() => {  
    resetManualScrollFlag();  
  }, [urlChatId, resetManualScrollFlag]);  
  
  // UI event handlers
  const handleFormSubmit = (options: { thinkingEnabled?: boolean }) => {
    // e.preventDefault(); // This is now handled in ChatInputBar.tsx
    if (
      input.trim() &&
      chatPhase === 'READY' &&
      !streamChat.isStreaming &&
      !isReactTransitionPending
    ) {
      handleSendMessage(input, selectedModel, options); // Pass options through
    }
  };
  
  const handlePromptSelect = (promptText: string) => {
    if (chatPhase === 'READY' && !streamChat.isStreaming && !isReactTransitionPending) {
      setInput(promptText);
      // For prompts selected from UI, thinking is likely not explicitly toggled,
      // so we might send undefined or a default.
      // Assuming default behavior (no thinking toggle explicitly set for these).
      handleSendMessage(promptText, selectedModel, { thinkingEnabled: undefined });
    }  
  };  
  
  const isRemixNavigating = remixNavigation.state !== 'idle';  
  const isContentReady =  
    (chatPhase === 'READY' && !isRemixNavigating && !isReactTransitionPending) ||  
    (isNewChatTransitioning && streamChat.messages.length > 0);  
  const childKey = urlChatId || 'new-chat-page-active';  
  
  return (  
    <div className="flex flex-col h-full w-full">  
      <div ref={containerRef} className="flex-grow overflow-y-auto overflow-x-hidden relative">  
        <div  
          style={{  
            opacity: isContentReady ? 1 : 0,  
            transition: 'opacity 0.2s ease-in-out',  
            minHeight: '100%',  
            display: 'flex',  
            flexDirection: 'column',  
          }}  
          className="w-full"  
        >  
          <div className="max-w-4xl mx-auto w-full flex-grow flex flex-col">  
            {streamChat.messages.length === 0 ? (  
              <InitialGreeting />  
            ) : (  
              <MessageList  
                key={`ml-${childKey}`}  
                messages={streamChat.messages}  
                isLoading={  
                  streamChat.isStreaming &&  
                  streamChat.messages[streamChat.messages.length - 1]?.role === 'assistant' &&  
                  streamChat.messages[streamChat.messages.length - 1]?.isLoading === true  
                }  
                isInitialHistoryLoading={false}  
                scrollEndRef={endRef}  
              />  
            )}  
          </div>  
        </div>  
  
        {showScrollDownButton && (  
          <div className="sticky bottom-4 w-full flex justify-center pointer-events-none z-30">  
            <div className="max-w-4xl w-full flex justify-end pointer-events-auto px-4">  
              <button  
                onClick={() => scrollToBottom('smooth')}  
                className="p-2 bg-card border border-border rounded-full shadow-lg hover:bg-muted focus:outline-none focus-visible:ring-2 focus-visible:ring-primary focus-visible:ring-offset-2 focus-visible:ring-offset-background transition-all duration-150 ease-in-out animate-fade-in"  
                aria-label="Scroll to latest messages"  
                title="Scroll to latest messages"  
                style={{ minWidth: 36, minHeight: 36, width: 36, height: 36 }}  
              >  
                <FiArrowDown size={16} aria-hidden="true" />  
              </button>  
            </div>  
          </div>  
        )}  
      </div>  
  
      <div className="flex-shrink-0 bg-background border-t border-border">  
        <div className="max-w-4xl mx-auto w-full p-2 md:p-3">  
          <ChatInputBar  
            key={`cib-${childKey}`}  
            input={input}  
            onInputChange={e => setInput(e.target.value)}  
            onSubmit={handleFormSubmit}  
            isLoading={  
              chatPhase !== 'READY' ||  
              streamChat.isStreaming ||  
              isRemixNavigating ||  
              isReactTransitionPending  
            }  
            availableModels={AImodels}  
            selectedModel={selectedModel}  
            onModelChange={handleModelChange}  
          />  
        </div>  
      </div>  
    </div>  
  );  
}  
---- app/routes/__app.tsx ----
// app/routes/__app.tsx
import type { LoaderFunctionArgs, MetaFunction } from "@remix-run/node";
import { json } from "@remix-run/node";
import { Outlet, useLoaderData } from "@remix-run/react";

import { requireAuth, type AuthenticatedUserDetails } from "~/lib/auth.server";
import { AppSidebar } from "~/components/app-sidebar";
import { SidebarProvider, SidebarInset, SidebarTrigger } from "~/components/ui/sidebar";
import type { NavItem } from "~/components/sidebar-nav";
import { Separator } from "~/components/ui/separator";
import { StreamingChatProvider } from "~/components/chat/streaming-chat-context";
import { SidebarChatHistoryProvider } from "~/components/sidebar-chat-history-context";
// ADD THIS IMPORT

export interface AppLoaderData {
  user: AuthenticatedUserDetails;
  appName: string;
  mainNavItems: NavItem[];
}

export async function loader({ request }: LoaderFunctionArgs) {
  await requireAuth(request);
  return json<AppLoaderData>({
    user: {
      id: "dummy",
      name: "Dummy",
      email: "dummy@example.com",
      avatar_url: "/avatars/default.png",
    },
    appName: "Krivi AI",
    mainNavItems: [],
  });
}

export const meta: MetaFunction = () => [  
  { title: "Krivi AI | Ignite & Flow" }  
];  

export default function AppLayout() {
  const { user, appName, mainNavItems } = useLoaderData<typeof loader>();
  const sidebarUser = {
    name: user.name,
    email: user.email,
    avatar: "/avatars/default.png",
  };

  return (
    // WRAP THE ENTIRE SIDEBAR PROVIDER (OR JUST THE OUTLET PART IF SIDEBAR IS NOT CHAT RELATED)
    // WITH STREAMINGCHATPROVIDER. For chat apps, often the whole app structure is relevant.
    <SidebarChatHistoryProvider>
      <StreamingChatProvider>
        <SidebarProvider>
          <AppSidebar
            user={sidebarUser}
            appName={appName}
            mainNav={mainNavItems}
          />
          <SidebarInset>
            <div className="relative flex flex-col h-[100dvh] min-h-0 w-full">
              <header
                className="  
                sticky top-0 left-0 right-0 z-30 flex  
                h-[41px] md:h-[62px]  
                shrink-0 items-center gap-2 border-b border-border bg-background  
              "
              >
                <div className="flex items-center gap-2 px-4">
                  <SidebarTrigger className="-ml-1" />
                  <Separator orientation="vertical" className="mr-2 h-4 bg-border" />
                </div>
              </header>
              <main className="relative flex-1 min-h-0 w-full flex flex-col">
                {/* Outlet is where your /chat and /chat/:id routes render */}
                <Outlet />
              </main>
            </div>
          </SidebarInset>
        </SidebarProvider>
      </StreamingChatProvider>
    </SidebarChatHistoryProvider>
  );
}
---- app/routes/__app.chat.$chatId.tsx ----
// app/routes/__app.chat.$chatId.tsx
import { useLoaderData, useLocation, useParams } from "@remix-run/react";
import { requireAuth } from "~/lib/auth.server";
import { ChatPageLayout } from "~/components/chat/ChatPageLayout";
import type { Message } from "~/components/chat/MessageItem";
import { fetchWithHeaders, getApiUrl } from "~/lib/api.config"; // Import getApiUrl
import { json, LoaderFunctionArgs } from "@remix-run/node";
import { normalizeMessagesForUI } from "~/components/chat/streaming-chat-context";


interface LoaderData {
  chatId: string;
  initialMessages: Message[];
  error?: string;
}

export async function loader({ request, params }: LoaderFunctionArgs): Promise<ReturnType<typeof json<LoaderData>>> {
  await requireAuth(request);
  const chatId = params.chatId;

  if (!chatId) {
    throw new Response("Chat ID missing in params", { status: 404 });
  }

  let messagesFromHistory: Message[] = [];
  // Construct URL using getApiUrl and append dynamic parts
  const baseHistoryUrl = getApiUrl('CHAT_HISTORY_BASE');
  const historyUrl = `${baseHistoryUrl.replace(/\/$/, '')}/${chatId}/history?limit=50`;

  try {
    const response = await fetchWithHeaders(historyUrl, {
      method: 'GET',
      headers: { 'Cookie': request.headers.get('Cookie') || '' },
    });

    if (response.ok) {
      const data = await response.json();
      if (data.messages && Array.isArray(data.messages)) {
        // Preserve all fields including thought, query for normalization
        const rawMessages = data.messages.map((msg: any) => ({
          ...msg,
          id: msg.id || crypto.randomUUID(),
          role: msg.role,
          content: msg.content,
          timestamp: msg.createdAt || msg.timestamp ? new Date(msg.createdAt || msg.timestamp).getTime() : undefined,
        }));
        messagesFromHistory = normalizeMessagesForUI(rawMessages);
      }
    } else {
      console.error(`Failed to fetch chat history for ${chatId}: ${response.status} ${response.statusText}`);
      return json({ chatId, initialMessages: [], error: `Failed to load history: ${response.status}` });
    }
  } catch (error: any) {
    console.error(`Error fetching chat history for ${chatId}:`, error);
    return json({ chatId, initialMessages: [], error: `Error loading chat: ${error.message}` });
  }
  return json({ chatId, initialMessages: messagesFromHistory });
}


export default function ChatWithIdPage() {
  const loaderData = useLoaderData<LoaderData>();
  const location = useLocation();
  const params = useParams(); // Use params for the key and current ID

  const navState = location.state as { initialMessages?: Message[], fromNewChatFlow?: boolean } | null;
  
  // Default to loader data. ChatPageLayout will further refine based on context and navState.
  let finalInitialMessages = loaderData.initialMessages;

  // This logic is simplified because ChatPageLayout's Effect 1 now has more robust handling
  // of messages from navState vs. loaderData vs. existing context state.
  if (navState?.fromNewChatFlow && navState.initialMessages && params.chatId === loaderData.chatId) {
      // We can still prefer navState messages if it's an immediate navigation
      // and ChatPageLayout will reconcile with context.
      finalInitialMessages = navState.initialMessages;
  }
  
  if (loaderData.error) {
    console.error("Error in loader for ChatWithIdPage:", loaderData.error);
  }

  return (
    <ChatPageLayout
      key={params.chatId} 
      initialChatIdFromLoader={loaderData.chatId} // Pass loader's chatId
      initialMessagesProp={finalInitialMessages}
    />
  );
}
---- app/routes/login.tsx ----
// app/routes/login.tsx
import type { LoaderFunctionArgs, MetaFunction } from "@remix-run/node";
import { json, redirect } from "@remix-run/node";
import { useLoaderData, useSearchParams } from "@remix-run/react";
import { FaGoogle } from "react-icons/fa";

import { Button } from "~/components/ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardFooter,
  CardHeader,
  CardTitle,
} from "~/components/ui/card";
import {
  checkAuth,
  refreshTokens,
  isAuthenticated,
  isRefreshable,
  type AuthStatus, // Type import is fine from .server files
} from "~/lib/auth.server";
import { getApiUrl } from "~/lib/api.config"; // Import getApiUrl from client-safe config
import { useIsMobile } from "~/hooks/use-mobile";

export const meta: MetaFunction = () => {
  return [{ title: "Sign In" }];
};

export async function loader({ request }: LoaderFunctionArgs) {
  const url = new URL(request.url);
  const responseHeaders = new Headers();

  let authStatus = await checkAuth(request);

  if (isRefreshable(authStatus)) {
    console.log("[Login Loader] Token refresh required. Attempting refresh...");
    const { ok, setCookieHeader } = await refreshTokens(request);
    if (ok && setCookieHeader) {
      responseHeaders.append("Set-Cookie", setCookieHeader);
      const destination = url.pathname + url.search;
      console.log(`[Login Loader] Refresh successful. Redirecting to ${destination} to apply new cookies.`);
      throw redirect(destination, { headers: responseHeaders });
    }
    authStatus = await checkAuth(request); // Re-check auth after failed refresh
    console.log("[Login Loader] Refresh failed or no cookies set. New auth status:", authStatus.status);
  }

  if (isAuthenticated(authStatus)) {
    const next = url.searchParams.get("next") || "/"; // Default to app's root
    console.log(`[Login Loader] User already authenticated. Redirecting to: ${next}`);
    throw redirect(next, { headers: responseHeaders });
  }

  return json({ authStatus }, { headers: responseHeaders });
}

export default function LoginPage() {  
  const { authStatus } = useLoaderData<typeof loader>();  
  const [searchParams] = useSearchParams();  
  const isMobile = useIsMobile();  
  
  const googleLoginUrl = getApiUrl("GOOGLE_LOGIN");  
  const nextParam = searchParams.get("next");  
  const finalGoogleLoginUrl = nextParam  
    ? `${googleLoginUrl}?final_redirect_path=${encodeURIComponent(nextParam)}`  
    : googleLoginUrl;  
  
  // Define only the errors we want to show to the user for login-specific issues
  const LOGIN_SPECIFIC_ERROR_MESSAGES: Record<string, string> = {
    session_terminated: "Your session has been terminated. Please sign in again.",
    invalid_or_expired_tokens: "Your session is invalid or has expired. Please sign in again.",
    // Add any other specific login-related errors that should be user-visible here.
    // For example, if your backend can return "invalid_credentials":
    // "invalid_credentials": "The username or password you entered is incorrect.",
  };

  const displayMessage = searchParams.get("message"); // For general messages, not errors
  let determinedErrorKey: string | null | undefined = searchParams.get("error_description") || searchParams.get("error");

  // If no error key from URL params, try to get it from authStatus
  if (!determinedErrorKey && authStatus) {
    // Only consider 'login_required' or 'error' statuses for deriving an error key from authStatus.reason
    if (authStatus.status === "login_required" || authStatus.status === "error") {
      determinedErrorKey = authStatus.reason; // authStatus.reason might be undefined or a non-displayable code
    }
  }

  // Map the determinedErrorKey to a user-friendly message if it's a known login-specific error
  // Otherwise, errorReason will be an empty string, suppressing generic/unknown errors.
  const errorReason = determinedErrorKey ? (LOGIN_SPECIFIC_ERROR_MESSAGES[determinedErrorKey] ?? "") : "";
  
  return (  
    <div className="flex min-h-screen items-center justify-center bg-background px-4 py-12">  
      <Card className="w-full max-w-md shadow-xl">  
        <CardHeader className="text-center">  
          <CardTitle className="text-3xl font-bold tracking-tight text-primary">  
            Access Your Account  
          </CardTitle>  
          <CardDescription className="text-muted-foreground pt-2">  
            Continue with Google to securely sign in.  
          </CardDescription>  
        </CardHeader>  
        <CardContent className="space-y-6 pt-6">  
          {errorReason && (  
            <div className="rounded-md border border-destructive/50 bg-destructive/10 p-3 text-center text-sm text-destructive">  
              <p>{errorReason}</p>  
            </div>  
          )}  
          {displayMessage && !errorReason && (  
            <div className="rounded-md border border-primary/50 bg-primary/10 p-3 text-center text-sm text-primary">  
              <p>{displayMessage}</p>  
            </div>  
          )}  
          <Button  
            asChild  
            size={isMobile ? "lg" : "lg"}  
            className="w-full bg-primary text-primary-foreground hover:bg-primary/90 text-lg py-6"  
          >  
            <a href={finalGoogleLoginUrl} className="flex items-center justify-center gap-3">  
              <FaGoogle className="h-5 w-5" />  
              Sign in with Google  
            </a>  
          </Button>  
        </CardContent>  
        <CardFooter className="flex-col items-center text-center pt-6">  
          <p className="text-xs text-muted-foreground">  
            By proceeding, you agree to our Terms of Service and Privacy Policy.  
          </p>  
        </CardFooter>  
      </Card>  
    </div>  
  );  
}  
---- app/routes/__app._index.tsx ----
// app/routes/__app._index.tsx
import { json, LoaderFunctionArgs, MetaFunction } from "@remix-run/node";
import { useLoaderData } from "@remix-run/react";
import { ChatPageLayout } from "~/components/chat/ChatPageLayout";
import { requireAuth } from "~/lib/auth.server";
import type { Message } from "~/components/chat/MessageItem";

export const meta: MetaFunction = () => [{ title: "Krivi AI" }];  


export async function loader({ request }: LoaderFunctionArgs) {
  await requireAuth(request);
  return json({
    initialChatId: null,
    initialMessages: [],
  });
}

export default function AppRootNewChatPage() {
  const { initialChatId, initialMessages } = useLoaderData<{
    initialChatId: null;
    initialMessages: Message[];
  }>();

  return (
    <ChatPageLayout
      key="new-chat-page" // Stable key for the new chat page instance
      initialChatIdFromLoader={initialChatId}
      initialMessagesProp={initialMessages}
    />
  );
}
---- app/hooks/useChatSessionMessages.ts ----
// app/hooks/useChatSessionMessages.ts  
import { useState, useEffect } from 'react';  
import { Message } from '~/components/chat/MessageItem';  
  
type ChatLoadingPhase = 'INITIALIZING' | 'PREPARING_CONTENT' | 'READY';  
  
export function useChatSessionMessages({  
  urlChatId,  
  initialMessagesProp,  
  streamChat,  
  location,  
  remixNavigation,  
  navigate,  
  startReactTransition,  
  isNewChatTransitioning,  
  setIsNewChatTransitioning,  
  scrollToBottom,  
}: {  
  urlChatId: string | null;  
  initialMessagesProp: Message[];  
  streamChat: any;  
  location: any;  
  remixNavigation: any;  
  navigate: any;  
  startReactTransition: any;  
  isNewChatTransitioning: boolean;  
  setIsNewChatTransitioning: (v: boolean) => void;  
  scrollToBottom: (behavior: ScrollBehavior) => void;  
}) {  
  const [chatPhase, setChatPhase] = useState<ChatLoadingPhase>('INITIALIZING');  
  const [hasInitialized, setHasInitialized] = useState(false);  
  
  useEffect(() => {  
    if (hasInitialized && remixNavigation.state !== 'idle') return;  
  
    const navState = location.state as { fromNewChatFlow?: boolean; initialMessages?: Message[] } | null;  
  
    if (isNewChatTransitioning && !urlChatId) return; // Corrected: pass as prop  
  
    setChatPhase('INITIALIZING');  
  
    if (urlChatId) {  
      let messagesToUse: Message[] = initialMessagesProp;  
  
      if (  
        streamChat.activeStreamChatId === urlChatId &&  
        streamChat.messages.length > 0 &&  
        initialMessagesProp.length === 0  
      ) {  
        messagesToUse = [...streamChat.messages];  
      }  
      if (navState?.fromNewChatFlow && streamChat.activeStreamChatId === urlChatId) {  
        messagesToUse = [...streamChat.messages];  
      } else if (navState?.fromNewChatFlow && navState.initialMessages) {  
        messagesToUse = navState.initialMessages;  
      } else if (streamChat.currentUIFocusChatId !== urlChatId) {  
        if (!streamChat.isStreaming || streamChat.activeStreamChatId !== urlChatId) {  
          streamChat.clearStreamState();  
        }  
      }  
      streamChat.setMessagesForContext(messagesToUse, urlChatId);  
  
      if (navState?.fromNewChatFlow) {  
        startReactTransition(() => {  
          const { state, ...restOfLocation } = location;  
          const { fromNewChatFlow: _fNCF, initialMessages: _iM, ...newStateWithoutFlow } = (state as any) || {};  
          navigate(restOfLocation, {  
            replace: true,  
            state: Object.keys(newStateWithoutFlow).length > 0 ? newStateWithoutFlow : undefined,  
          });  
        });  
        setIsNewChatTransitioning(false);  
      }  
      setChatPhase('PREPARING_CONTENT');  
    } else if (!urlChatId) {  
      if (  
        streamChat.currentUIFocusChatId !== null ||  
        (streamChat.messages.length > 0 && !streamChat.isStreaming)  
      ) {  
        streamChat.clearStreamState();  
      }  
      setChatPhase('READY');  
    }  
    setHasInitialized(true);  
    // eslint-disable-next-line react-hooks/exhaustive-deps  
  }, [urlChatId, initialMessagesProp, location.pathname, isNewChatTransitioning]);  
  
  useEffect(() => {  
    return () => {  
      setHasInitialized(false);  
    };  
  }, [location.pathname]);  
  
  useEffect(() => {  
    if (  
      chatPhase === 'PREPARING_CONTENT' &&  
      streamChat.currentUIFocusChatId === urlChatId &&  
      urlChatId  
    ) {  
      startReactTransition(() => {  
        setChatPhase('READY');  
        const navState = location.state as { fromNewChatFlow?: boolean } | null;  
        if (!navState?.fromNewChatFlow) {  
          requestAnimationFrame(() => scrollToBottom('auto'));  
        }  
      });  
    }  
  }, [  
    chatPhase,  
    urlChatId,  
    streamChat.currentUIFocusChatId,  
    scrollToBottom,  
    location.state,  
    startReactTransition,  
  ]);  
  
  return {  
    chatPhase,  
    setChatPhase,  
  };  
}  
---- app/hooks/useChatSendMessage.ts ----
import { useCallback } from 'react';  
import { v4 as uuidv4 } from 'uuid';  
import { Message } from '~/components/chat/MessageItem';
import type { AIModelConfig } from '~/lib/ai-models';  
  
export function useChatSendMessage({  
  streamChat,  
  urlChatId,  
  lastSelectedModelMapRef,  
  isReactTransitionPending,  
  chatPhase,  
  navigate,  
  startReactTransition,  
  setInput,  
  setIsNewChatTransitioning,  
  chatModelKey  
}: {  
  streamChat: any,  
  urlChatId: string | null,  
  lastSelectedModelMapRef: React.MutableRefObject<{[key: string]: AIModelConfig}>,  
  isReactTransitionPending: boolean,  
  chatPhase: string,  
  navigate: any,  
  startReactTransition: any,  
  setInput: (v: string) => void,  
  setIsNewChatTransitioning: (v: boolean) => void,  
  chatModelKey: string  
}) {  
  return useCallback(
    async (inputTextValue: string, modelConfig: AIModelConfig, options?: { thinkingEnabled?: boolean }) => {
      const trimmedInput = inputTextValue.trim();
      if (!trimmedInput || streamChat.isStreaming || isReactTransitionPending || chatPhase !== 'READY') {
        return;
      }
      setInput('');
      lastSelectedModelMapRef.current[chatModelKey] = modelConfig;
  
      const userMessage: Message = {
        id: crypto.randomUUID(),
        role: 'user',
        content: trimmedInput,
      };
      
      const thinkingEnabled = options?.thinkingEnabled;
  
      if (!urlChatId) {
        const newChatId = uuidv4();
        try {
          setIsNewChatTransitioning(true);
          streamChat.setMessagesForContext([userMessage], newChatId);
          const streamPromise = streamChat.startStream(trimmedInput, modelConfig, newChatId, thinkingEnabled);
          setTimeout(() => {
            const destinationPath = `/chat/${newChatId}`;
            startReactTransition(() => {
              navigate(destinationPath, {
                replace: true,
                state: { initialMessages: [userMessage], fromNewChatFlow: true },
              });
            });
          }, 50);
          await streamPromise;
        } catch (error) {
          console.error('Error in new chat flow:', error);
          setIsNewChatTransitioning(false);
        }
      } else {
        try {
          streamChat.setMessagesForContext([...streamChat.messages, userMessage], urlChatId);
          await streamChat.startStream(trimmedInput, modelConfig, urlChatId, thinkingEnabled);
        } catch (error) {
          console.error('Error in existing chat flow:', error);
        }
      }
    },
    [  
      streamChat,  
      urlChatId,  
      isReactTransitionPending,  
      chatPhase,  
      navigate,  
      startReactTransition,  
      chatModelKey  
    ]  
  );  
}  
---- app/hooks/use-mobile.tsx ----
import * as React from "react"

const MOBILE_BREAKPOINT = 768

export function useIsMobile() {
  const [isMobile, setIsMobile] = React.useState<boolean | undefined>(undefined)

  React.useEffect(() => {
    // Ensure window is defined (for SSR safety, though matchMedia is client-only)
    if (typeof window === 'undefined') {
      setIsMobile(false); // Default for server or non-browser env
      return;
    }

    const mql = window.matchMedia(`(max-width: ${MOBILE_BREAKPOINT - 1}px)`)
    const onChange = () => {
      setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)
    }
    // Add listener
    mql.addEventListener("change", onChange)
    // Set initial state
    setIsMobile(window.innerWidth < MOBILE_BREAKPOINT)
    // Clean up listener
    return () => mql.removeEventListener("change", onChange)
  }, [])

  return !!isMobile
}
---- app/hooks/useSidebarHistoryRefreshOnChatChange.ts ----
import { useEffect, useRef } from 'react';  
  
export function useSidebarHistoryRefreshOnChatChange(initialChatIdFromLoader: string | null, refreshChatHistory: () => void) {  
  const prevChatIdRef = useRef<string | null>(null);  
  
  useEffect(() => {  
    if (  
      prevChatIdRef.current === null && // previously on new chat  
      initialChatIdFromLoader !== null // now on an actual chat  
    ) {  
      refreshChatHistory();  
    }  
    prevChatIdRef.current = initialChatIdFromLoader;  
  }, [initialChatIdFromLoader, refreshChatHistory]);  
}  
---- app/hooks/usePerChatModelSelection.ts ----
import { useState, useEffect, useRef } from "react";  
import type { AIModelConfig } from '~/lib/ai-models';  
  
export function usePerChatModelSelection(chatKey: string, defaultModel: AIModelConfig) {  
  const mappingRef = useRef<{ [key: string]: AIModelConfig }>({});  
  const [selectedModel, setSelectedModel] = useState<AIModelConfig>(defaultModel);  
  
  useEffect(() => {  
    setSelectedModel(mappingRef.current[chatKey] ?? defaultModel);  
  }, [chatKey, defaultModel]);  
  
  const handleModelChange = (model: AIModelConfig) => {  
    setSelectedModel(model);  
    mappingRef.current[chatKey] = model;  
  };  
  
  return { selectedModel, handleModelChange };  
}  
---- app/hooks/useScrollToBottom.ts ----
// Modified useScrollToBottom.ts hook

import { useRef, useState, useEffect, useCallback } from 'react';
import { Message } from '~/components/chat/MessageItem';

const INTERSECTION_THRESHOLD_PX = 30;
const USER_SCROLL_DEBOUNCE_MS = 150;

export function useScrollToBottom(messages: Message[]) {
  const containerRef = useRef<HTMLDivElement | null>(null);
  const endRef = useRef<HTMLDivElement | null>(null);

  const [isAtBottom, setIsAtBottom] = useState(true);
  const [showScrollDownButton, setShowScrollDownButton] = useState(false);
  const scrollTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const userManuallyScrolled = useRef(false);
  const lastMessageCount = useRef(0);

  // Function to scroll to specific position
  const scrollToPosition = useCallback((position: number, behavior: ScrollBehavior = 'smooth') => {
    const scrollableContainer = containerRef.current;
    if (scrollableContainer) {
      scrollableContainer.scrollTo({
        top: position,
        behavior,
      });
    }
  }, []);

  // Complete scroll to bottom function (unchanged)
  const scrollToBottom = useCallback((behavior: ScrollBehavior = 'smooth') => {
    const scrollableContainer = containerRef.current;
    const bottomMarker = endRef.current;

    if (bottomMarker) {
      bottomMarker.scrollIntoView({ behavior });
    } else if (scrollableContainer) {
      scrollableContainer.scrollTo({
        top: scrollableContainer.scrollHeight,
        behavior,
      });
    }
    setIsAtBottom(true);
    setShowScrollDownButton(false);
  }, []);

  // New function for 30/70 scrolling
  const scrollToPartialView = useCallback((behavior: ScrollBehavior = 'smooth') => {
    const scrollableContainer = containerRef.current;
    if (!scrollableContainer || userManuallyScrolled.current) return;

    // Calculate the position that shows 30% previous content, 70% new content
    const containerHeight = scrollableContainer.clientHeight;
    const scrollHeight = scrollableContainer.scrollHeight;
    
    // Position to show 30% of previous content at the top
    // This means we want to position the scroll so that we're 70% down the way
    // from (scrollHeight - containerHeight) which is the maximum scroll position
    const newPosition = Math.max(
      0,
      (scrollHeight - containerHeight) * 0.7
    );
    
    scrollToPosition(newPosition, behavior);
  }, [scrollToPosition]);

  // Track user manual scrolling
  useEffect(() => {
    const scrollableContainer = containerRef.current;
    if (!scrollableContainer) return;

    const handleScroll = () => {
      // Consider any scroll during active interaction as manual
      userManuallyScrolled.current = true;
      
      if (scrollTimeoutRef.current) clearTimeout(scrollTimeoutRef.current);

      scrollTimeoutRef.current = setTimeout(() => {
        if (scrollableContainer) {
          const { scrollTop, scrollHeight, clientHeight } = scrollableContainer;
          const isNearBottom = scrollHeight - scrollTop - clientHeight < INTERSECTION_THRESHOLD_PX + 5;

          if (!isNearBottom) {
            if (!showScrollDownButton) setShowScrollDownButton(true);
            if (isAtBottom) setIsAtBottom(false);
          } else {
            if (showScrollDownButton) setShowScrollDownButton(false);
            if (!isAtBottom) setIsAtBottom(true);
            // Reset manual scroll flag when user scrolls back to bottom
            userManuallyScrolled.current = false;
          }
        }
      }, USER_SCROLL_DEBOUNCE_MS);
    };

    scrollableContainer.addEventListener('scroll', handleScroll, { passive: true });
    return () => {
      scrollableContainer.removeEventListener('scroll', handleScroll);
      if (scrollTimeoutRef.current) clearTimeout(scrollTimeoutRef.current);
    };
  }, [isAtBottom, showScrollDownButton]);

  // Handle new messages logic
  useEffect(() => {
    // Reset manual scroll flag on first render
    if (messages.length === 0) {
      userManuallyScrolled.current = false;
    }
    
    // If new message was added
    if (messages.length > lastMessageCount.current) {
      // If this is a user message, apply the partial view scroll
      const lastMessage = messages[messages.length - 1];
      
      // When a new user message is sent, do partial scroll
      if (lastMessage && lastMessage.role === 'user') {
        // Short delay to allow DOM to update
        setTimeout(() => scrollToPartialView(), 50);
      } 
      // When receiving AI response and user hasn't manually scrolled
      else if (lastMessage && lastMessage.role === 'assistant' && !userManuallyScrolled.current) {
        // If at bottom or was already showing partial view, maintain position
        if (isAtBottom) {
          setTimeout(() => scrollToBottom('auto'), 10);
        }
      }
      
      lastMessageCount.current = messages.length;
    }
  }, [messages, isAtBottom, scrollToBottom, scrollToPartialView]);

  // Observer to track if we're at bottom (unchanged)
  useEffect(() => {
    const scrollableContainer = containerRef.current;
    const bottomMarker = endRef.current;

    if (!scrollableContainer || !bottomMarker) {
      setIsAtBottom(true);
      setShowScrollDownButton(false);
      return;
    }

    const observer = new IntersectionObserver(
      ([entry]) => {
        const isCurrentlyIntersecting = entry.isIntersecting;
        setIsAtBottom(isCurrentlyIntersecting);
        setShowScrollDownButton(!isCurrentlyIntersecting);
      },
      {
        root: scrollableContainer,
        rootMargin: `0px 0px ${INTERSECTION_THRESHOLD_PX}px 0px`,
        threshold: 0.01,
      }
    );
    observer.observe(bottomMarker);

    if (
      scrollableContainer.scrollHeight > scrollableContainer.clientHeight &&
      scrollableContainer.scrollTop + scrollableContainer.clientHeight < scrollableContainer.scrollHeight - INTERSECTION_THRESHOLD_PX
    ) {
      setIsAtBottom(false);
      setShowScrollDownButton(true);
    } else {
      setIsAtBottom(true);
      setShowScrollDownButton(false);
    }

    return () => {
      observer.unobserve(bottomMarker);
      observer.disconnect();
    };
  }, [containerRef, endRef]);

  // Reset userManuallyScrolled flag when we navigate to a new chat
  const resetManualScrollFlag = useCallback(() => {
    userManuallyScrolled.current = false;
  }, []);

  return {
    containerRef,
    endRef,
    isAtBottom,
    showScrollDownButton,
    scrollToBottom,
    scrollToPartialView,
    resetManualScrollFlag
  };
}
---- app/routes/__app.tsx ----
// app/routes/__app.tsx
import type { LoaderFunctionArgs, MetaFunction } from "@remix-run/node";
import { json } from "@remix-run/node";
import { Outlet, useLoaderData } from "@remix-run/react";

import { requireAuth, type AuthenticatedUserDetails } from "~/lib/auth.server";
import { AppSidebar } from "~/components/app-sidebar";
import { SidebarProvider, SidebarInset, SidebarTrigger } from "~/components/ui/sidebar";
import type { NavItem } from "~/components/sidebar-nav";
import { Separator } from "~/components/ui/separator";
import { StreamingChatProvider } from "~/components/chat/streaming-chat-context";
import { SidebarChatHistoryProvider } from "~/components/sidebar-chat-history-context";
// ADD THIS IMPORT

export interface AppLoaderData {
  user: AuthenticatedUserDetails;
  appName: string;
  mainNavItems: NavItem[];
}

export async function loader({ request }: LoaderFunctionArgs) {
  await requireAuth(request);
  return json<AppLoaderData>({
    user: {
      id: "dummy",
      name: "Dummy",
      email: "dummy@example.com",
      avatar_url: "/avatars/default.png",
    },
    appName: "Krivi AI",
    mainNavItems: [],
  });
}

export const meta: MetaFunction = () => [  
  { title: "Krivi AI | Ignite & Flow" }  
];  

export default function AppLayout() {
  const { user, appName, mainNavItems } = useLoaderData<typeof loader>();
  const sidebarUser = {
    name: user.name,
    email: user.email,
    avatar: "/avatars/default.png",
  };

  return (
    // WRAP THE ENTIRE SIDEBAR PROVIDER (OR JUST THE OUTLET PART IF SIDEBAR IS NOT CHAT RELATED)
    // WITH STREAMINGCHATPROVIDER. For chat apps, often the whole app structure is relevant.
    <SidebarChatHistoryProvider>
      <StreamingChatProvider>
        <SidebarProvider>
          <AppSidebar
            user={sidebarUser}
            appName={appName}
            mainNav={mainNavItems}
          />
          <SidebarInset>
            <div className="relative flex flex-col h-[100dvh] min-h-0 w-full">
              <header
                className="  
                sticky top-0 left-0 right-0 z-30 flex  
                h-[41px] md:h-[62px]  
                shrink-0 items-center gap-2 border-b border-border bg-background  
              "
              >
                <div className="flex items-center gap-2 px-4">
                  <SidebarTrigger className="-ml-1" />
                  <Separator orientation="vertical" className="mr-2 h-4 bg-border" />
                </div>
              </header>
              <main className="relative flex-1 min-h-0 w-full flex flex-col">
                {/* Outlet is where your /chat and /chat/:id routes render */}
                <Outlet />
              </main>
            </div>
          </SidebarInset>
        </SidebarProvider>
      </StreamingChatProvider>
    </SidebarChatHistoryProvider>
  );
}
---- app/routes/__app.chat.$chatId.tsx ----
// app/routes/__app.chat.$chatId.tsx
import { useLoaderData, useLocation, useParams } from "@remix-run/react";
import { requireAuth } from "~/lib/auth.server";
import { ChatPageLayout } from "~/components/chat/ChatPageLayout";
import type { Message } from "~/components/chat/MessageItem";
import { fetchWithHeaders, getApiUrl } from "~/lib/api.config"; // Import getApiUrl
import { json, LoaderFunctionArgs } from "@remix-run/node";
import { normalizeMessagesForUI } from "~/components/chat/streaming-chat-context";


interface LoaderData {
  chatId: string;
  initialMessages: Message[];
  error?: string;
}

export async function loader({ request, params }: LoaderFunctionArgs): Promise<ReturnType<typeof json<LoaderData>>> {
  await requireAuth(request);
  const chatId = params.chatId;

  if (!chatId) {
    throw new Response("Chat ID missing in params", { status: 404 });
  }

  let messagesFromHistory: Message[] = [];
  // Construct URL using getApiUrl and append dynamic parts
  const baseHistoryUrl = getApiUrl('CHAT_HISTORY_BASE');
  const historyUrl = `${baseHistoryUrl.replace(/\/$/, '')}/${chatId}/history?limit=50`;

  try {
    const response = await fetchWithHeaders(historyUrl, {
      method: 'GET',
      headers: { 'Cookie': request.headers.get('Cookie') || '' },
    });

    if (response.ok) {
      const data = await response.json();
      if (data.messages && Array.isArray(data.messages)) {
        // Preserve all fields including thought, query for normalization
        const rawMessages = data.messages.map((msg: any) => ({
          ...msg,
          id: msg.id || crypto.randomUUID(),
          role: msg.role,
          content: msg.content,
          timestamp: msg.createdAt || msg.timestamp ? new Date(msg.createdAt || msg.timestamp).getTime() : undefined,
        }));
        messagesFromHistory = normalizeMessagesForUI(rawMessages);
      }
    } else {
      console.error(`Failed to fetch chat history for ${chatId}: ${response.status} ${response.statusText}`);
      return json({ chatId, initialMessages: [], error: `Failed to load history: ${response.status}` });
    }
  } catch (error: any) {
    console.error(`Error fetching chat history for ${chatId}:`, error);
    return json({ chatId, initialMessages: [], error: `Error loading chat: ${error.message}` });
  }
  return json({ chatId, initialMessages: messagesFromHistory });
}


export default function ChatWithIdPage() {
  const loaderData = useLoaderData<LoaderData>();
  const location = useLocation();
  const params = useParams(); // Use params for the key and current ID

  const navState = location.state as { initialMessages?: Message[], fromNewChatFlow?: boolean } | null;
  
  // Default to loader data. ChatPageLayout will further refine based on context and navState.
  let finalInitialMessages = loaderData.initialMessages;

  // This logic is simplified because ChatPageLayout's Effect 1 now has more robust handling
  // of messages from navState vs. loaderData vs. existing context state.
  if (navState?.fromNewChatFlow && navState.initialMessages && params.chatId === loaderData.chatId) {
      // We can still prefer navState messages if it's an immediate navigation
      // and ChatPageLayout will reconcile with context.
      finalInitialMessages = navState.initialMessages;
  }
  
  if (loaderData.error) {
    console.error("Error in loader for ChatWithIdPage:", loaderData.error);
  }

  return (
    <ChatPageLayout
      key={params.chatId} 
      initialChatIdFromLoader={loaderData.chatId} // Pass loader's chatId
      initialMessagesProp={finalInitialMessages}
    />
  );
}
---- app/routes/login.tsx ----
// app/routes/login.tsx
import type { LoaderFunctionArgs, MetaFunction } from "@remix-run/node";
import { json, redirect } from "@remix-run/node";
import { useLoaderData, useSearchParams } from "@remix-run/react";
import { FaGoogle } from "react-icons/fa";

import { Button } from "~/components/ui/button";
import {
  Card,
  CardContent,
  CardDescription,
  CardFooter,
  CardHeader,
  CardTitle,
} from "~/components/ui/card";
import {
  checkAuth,
  refreshTokens,
  isAuthenticated,
  isRefreshable,
  type AuthStatus, // Type import is fine from .server files
} from "~/lib/auth.server";
import { getApiUrl } from "~/lib/api.config"; // Import getApiUrl from client-safe config
import { useIsMobile } from "~/hooks/use-mobile";

export const meta: MetaFunction = () => {
  return [{ title: "Sign In" }];
};

export async function loader({ request }: LoaderFunctionArgs) {
  const url = new URL(request.url);
  const responseHeaders = new Headers();

  let authStatus = await checkAuth(request);

  if (isRefreshable(authStatus)) {
    console.log("[Login Loader] Token refresh required. Attempting refresh...");
    const { ok, setCookieHeader } = await refreshTokens(request);
    if (ok && setCookieHeader) {
      responseHeaders.append("Set-Cookie", setCookieHeader);
      const destination = url.pathname + url.search;
      console.log(`[Login Loader] Refresh successful. Redirecting to ${destination} to apply new cookies.`);
      throw redirect(destination, { headers: responseHeaders });
    }
    authStatus = await checkAuth(request); // Re-check auth after failed refresh
    console.log("[Login Loader] Refresh failed or no cookies set. New auth status:", authStatus.status);
  }

  if (isAuthenticated(authStatus)) {
    const next = url.searchParams.get("next") || "/"; // Default to app's root
    console.log(`[Login Loader] User already authenticated. Redirecting to: ${next}`);
    throw redirect(next, { headers: responseHeaders });
  }

  return json({ authStatus }, { headers: responseHeaders });
}

export default function LoginPage() {  
  const { authStatus } = useLoaderData<typeof loader>();  
  const [searchParams] = useSearchParams();  
  const isMobile = useIsMobile();  
  
  const googleLoginUrl = getApiUrl("GOOGLE_LOGIN");  
  const nextParam = searchParams.get("next");  
  const finalGoogleLoginUrl = nextParam  
    ? `${googleLoginUrl}?final_redirect_path=${encodeURIComponent(nextParam)}`  
    : googleLoginUrl;  
  
  // Define only the errors we want to show to the user for login-specific issues
  const LOGIN_SPECIFIC_ERROR_MESSAGES: Record<string, string> = {
    session_terminated: "Your session has been terminated. Please sign in again.",
    invalid_or_expired_tokens: "Your session is invalid or has expired. Please sign in again.",
    // Add any other specific login-related errors that should be user-visible here.
    // For example, if your backend can return "invalid_credentials":
    // "invalid_credentials": "The username or password you entered is incorrect.",
  };

  const displayMessage = searchParams.get("message"); // For general messages, not errors
  let determinedErrorKey: string | null | undefined = searchParams.get("error_description") || searchParams.get("error");

  // If no error key from URL params, try to get it from authStatus
  if (!determinedErrorKey && authStatus) {
    // Only consider 'login_required' or 'error' statuses for deriving an error key from authStatus.reason
    if (authStatus.status === "login_required" || authStatus.status === "error") {
      determinedErrorKey = authStatus.reason; // authStatus.reason might be undefined or a non-displayable code
    }
  }

  // Map the determinedErrorKey to a user-friendly message if it's a known login-specific error
  // Otherwise, errorReason will be an empty string, suppressing generic/unknown errors.
  const errorReason = determinedErrorKey ? (LOGIN_SPECIFIC_ERROR_MESSAGES[determinedErrorKey] ?? "") : "";
  
  return (  
    <div className="flex min-h-screen items-center justify-center bg-background px-4 py-12">  
      <Card className="w-full max-w-md shadow-xl">  
        <CardHeader className="text-center">  
          <CardTitle className="text-3xl font-bold tracking-tight text-primary">  
            Access Your Account  
          </CardTitle>  
          <CardDescription className="text-muted-foreground pt-2">  
            Continue with Google to securely sign in.  
          </CardDescription>  
        </CardHeader>  
        <CardContent className="space-y-6 pt-6">  
          {errorReason && (  
            <div className="rounded-md border border-destructive/50 bg-destructive/10 p-3 text-center text-sm text-destructive">  
              <p>{errorReason}</p>  
            </div>  
          )}  
          {displayMessage && !errorReason && (  
            <div className="rounded-md border border-primary/50 bg-primary/10 p-3 text-center text-sm text-primary">  
              <p>{displayMessage}</p>  
            </div>  
          )}  
          <Button  
            asChild  
            size={isMobile ? "lg" : "lg"}  
            className="w-full bg-primary text-primary-foreground hover:bg-primary/90 text-lg py-6"  
          >  
            <a href={finalGoogleLoginUrl} className="flex items-center justify-center gap-3">  
              <FaGoogle className="h-5 w-5" />  
              Sign in with Google  
            </a>  
          </Button>  
        </CardContent>  
        <CardFooter className="flex-col items-center text-center pt-6">  
          <p className="text-xs text-muted-foreground">  
            By proceeding, you agree to our Terms of Service and Privacy Policy.  
          </p>  
        </CardFooter>  
      </Card>  
    </div>  
  );  
}  
---- app/routes/__app._index.tsx ----
// app/routes/__app._index.tsx
import { json, LoaderFunctionArgs, MetaFunction } from "@remix-run/node";
import { useLoaderData } from "@remix-run/react";
import { ChatPageLayout } from "~/components/chat/ChatPageLayout";
import { requireAuth } from "~/lib/auth.server";
import type { Message } from "~/components/chat/MessageItem";

export const meta: MetaFunction = () => [{ title: "Krivi AI" }];  


export async function loader({ request }: LoaderFunctionArgs) {
  await requireAuth(request);
  return json({
    initialChatId: null,
    initialMessages: [],
  });
}

export default function AppRootNewChatPage() {
  const { initialChatId, initialMessages } = useLoaderData<{
    initialChatId: null;
    initialMessages: Message[];
  }>();

  return (
    <ChatPageLayout
      key="new-chat-page" // Stable key for the new chat page instance
      initialChatIdFromLoader={initialChatId}
      initialMessagesProp={initialMessages}
    />
  );
}
---- app/lib/ai-models.ts ----
// app/lib/ai-models.ts
export interface AIModelConfig {
  displayName: string;
  model: string;
  provider: string;
  requestPayload: Record<string, any>; // Added for model-specific payloads
  isDefault?: boolean; // Optional: useful for selecting default
  uiOptions?: { // For model-specific UI elements
    thinkingToggleSettings?: {
      enabledBudget: number;
      disabledBudget: number;
    };
  };
}

// Import models from their respective files
// import { azureModels } from './model-list/azure-models'; // Old import
// import { googleModels } from './model-list/google-models'; // Old import
import { cerebrasModels } from './model-list/cerebras-models'; // Keeping this as its structure hasn't changed

// New model imports
import { gemini25FlashPreview0520Model } from './model-list/google/gemini-2.5-flash-preview-05-20';
import { gemini20FlashModel } from './model-list/google/gemini-2.0-flash';
import { gpt41Model } from './model-list/azure/gpt-4.1';
import { API_BASE_URL } from '~/lib/api.config'; // Import API_BASE_URL

// If you add more providers, import them here

// Combine all models into the main AImodels array
export const AImodels: AIModelConfig[] = [
  // ...azureModels, // Old spread
  // ...googleModels, // Old spread
  gpt41Model, // Add new Azure model
  gemini25FlashPreview0520Model, // Add new Google model
  gemini20FlashModel, // Add new Google model
  ...cerebrasModels,
  // Spread other imported model arrays here
  // Add more models here as needed (if they don't fit a provider category or are one-offs)
];

// Select default based on isDefault flag or fallback
// This logic remains the same and works on the combined AImodels array
export const defaultModelConfig: AIModelConfig = AImodels.find(m => m.isDefault) || AImodels[0];

// These constants remain as they are global to the AI service
export const defaultSystemPrompt = "You are a helpful assistant.";

// Use API_BASE_URL to construct these URLs
export const API_STREAM_URL = API_BASE_URL ? `${API_BASE_URL}/api/chat/stream` : "/api/chat/stream";
export const API_HISTORY_URL_BASE = API_BASE_URL ? `${API_BASE_URL}/api/chat` : "/api/chat"; // Note: path adjusted, specific endpoint like /:chatId/history will be appended by calling code